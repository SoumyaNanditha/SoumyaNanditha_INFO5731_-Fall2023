{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSdXHuqnwv9"
   },
   "source": [
    "# **INFO5731 Assignment Two**\n",
    "\n",
    "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWxodXh5n4xF"
   },
   "source": [
    "# **Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TenBkDJ5n95k"
   },
   "source": [
    "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
    "\n",
    "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon.\n",
    "\n",
    "(2) Collect the top 10000 User Reviews of a film recently in 2023 or 2022 (you can choose any film) from IMDB.\n",
    "\n",
    "(3) Collect all the reviews of the top 1000 most popular software from [G2](https://www.g2.com/) or [Capterra](https://www.capterra.com/)\n",
    "\n",
    "(4) Collect the abstracts of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from [Semantic Scholar](https://www.semanticscholar.org).\n",
    "\n",
    "(5) Collect all the information of the 904 narrators in the [Densho Digital Repository](https://ddr.densho.org/narrators/).\n",
    "\n",
    "(6) Collect the top 10000 reddits by using a hashtag (you can use any hashtag) from Reddits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PuFPKhC0m1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews have been scraped and saved to imdb_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Define the URL of the IMDb page with user reviews\n",
    "url = \"https://www.imdb.com/title/tt6791350/reviews/?ref_=tt_ql_2\"\n",
    "\n",
    "# Create a CSV file to store the data\n",
    "csv_filename = \"imdb_reviews.csv\"\n",
    "csv_file = open(csv_filename, 'w', encoding='utf-8', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Title\", \"User\", \"Date\", \"Rating\", \"Review\"])\n",
    "\n",
    "# Function to scrape and save reviews\n",
    "def scrape_reviews(url, csv_writer):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        reviews = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "\n",
    "        for review in reviews:\n",
    "            title = review.find(\"a\", class_=\"title\").text.strip()\n",
    "            user = review.find(\"span\", class_=\"display-name-link\").text.strip()\n",
    "            date = review.find(\"span\", class_=\"review-date\").text.strip()\n",
    "            rating = review.find(\"span\", class_=\"rating-other-user-rating\").text.strip()\n",
    "            review_text = review.find(\"div\", class_=\"text\").text.strip().replace(\"\\n\", \" \")\n",
    "            csv_writer.writerow([title, user, date, rating, review_text])\n",
    "\n",
    "# Scrape multiple pages of reviews (adjust the range accordingly)\n",
    "for page_num in range(1, 500):\n",
    "    page_url = f\"{url}&start={page_num * 10}\"\n",
    "    scrape_reviews(page_url, csv_writer)\n",
    "\n",
    "csv_file.close()\n",
    "print(\"Reviews have been scraped and saved to\", csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfpMRCrRwN6Z"
   },
   "source": [
    "# **Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dCQEbDawWCw"
   },
   "source": [
    "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
    "\n",
    "(1) Remove noise, such as special characters and punctuations.\n",
    "\n",
    "(2) Remove numbers.\n",
    "\n",
    "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
    "\n",
    "(4) Lowercase all texts\n",
    "\n",
    "(5) Stemming.\n",
    "\n",
    "(6) Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\soumya nanditha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vATjQNTY8buA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\soumya\n",
      "[nltk_data]     nanditha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\soumya\n",
      "[nltk_data]     nanditha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\soumya\n",
      "[nltk_data]     nanditha\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data has been cleaned and saved to imdb_reviews_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize the stopwords, stemmer, and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize the text and remove stopwords\n",
    "    words = [word for word in text.lower().split() if word not in stop_words]\n",
    "    # Stem and lemmatize each word\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words]\n",
    "    # Join the cleaned words back into a string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Load the CSV data into a pandas DataFrame\n",
    "csv_filename = \"imdb_reviews.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Clean and preprocess the 'Review' column\n",
    "df['Cleaned Review'] = df['Review'].apply(clean_text)\n",
    "\n",
    "# Save the DataFrame with cleaned data to a new CSV file\n",
    "cleaned_csv_filename = \"imdb_reviews_cleaned.csv\"\n",
    "df.to_csv(cleaned_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Text data has been cleaned and saved to\", cleaned_csv_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5mmYIfN8eYV"
   },
   "source": [
    "# **Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsi2y4z88ngX"
   },
   "source": [
    "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes:\n",
    "\n",
    "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
    "\n",
    "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
    "\n",
    "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy>=2.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from en-core-web-sm==2.2.0) (3.7.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (8.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.10.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (4.64.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.3.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (61.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (6.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.21.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.10.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.2.0->en-core-web-sm==2.2.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2021.10.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.2.0->en-core-web-sm==2.2.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.2.0->en-core-web-sm==2.2.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.0-py3-none-any.whl size=12019121 sha256=a81936853806a3c4b885af43b50299dcbc632739d3431e683ebe3cc7db6df93a\n",
      "  Stored in directory: c:\\users\\soumya nanditha\\appdata\\local\\pip\\cache\\wheels\\02\\87\\47\\4d729a97cc46afa46135595b4de32d01461f05947df39166d7\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from en_core_web_sm) (3.7.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (6.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (61.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (0.3.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (1.10.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (0.10.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (2.4.6)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (1.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (1.21.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (8.2.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en_core_web_sm) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=2.2.0->en_core_web_sm) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.2.0->en_core_web_sm) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.2.0->en_core_web_sm) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.2.0->en_core_web_sm) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=2.2.0->en_core_web_sm) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=2.2.0->en_core_web_sm) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.2.0->en_core_web_sm) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.2.0->en_core_web_sm) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gzNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz (13.7 MB)\n",
      "Collecting spacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy-3.0.9-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (6.4.0)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Using cached thinc-8.0.17-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (61.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.21.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.64.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-3.0.0-py3-none-any.whl size=13704321 sha256=bbf411156c735bc56d38c9a360b27461c950331e6e2b8c630a185b32019b1c6e\n",
      "  Stored in directory: c:\\users\\soumya nanditha\\appdata\\local\\pip\\cache\\wheels\\88\\16\\62\\706709a80d48c983fffc44547114a933c464cd032e19378fb2\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: thinc, spacy, en-core-web-sm\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.1\n",
      "    Uninstalling thinc-8.2.1:\n",
      "      Successfully uninstalled thinc-8.2.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\soumya nanditha\\\\anaconda3\\\\Lib\\\\site-packages\\\\~hinc\\\\backends\\\\cblas.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (6.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\soumya nanditha\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QQKnPjPDHJHr"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from C:\\Users\\soumya nanditha\\anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-2.2.0\\config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the spaCy English language model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Read the cleaned text from the CSV file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimdb_reviews_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_package(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\en_core_web_sm\\__init__.py:12\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_init_py(\u001b[38;5;18m__file__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    536\u001b[0m config_path \u001b[38;5;241m=\u001b[39m model_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config, for_overrides\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 538\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[0;32m    540\u001b[0m     config,\n\u001b[0;32m    541\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    546\u001b[0m )\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(path, overrides, interpolate)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m--> 714\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE053\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mconfig_path, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig file\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\u001b[38;5;241m.\u001b[39mfrom_disk(\n\u001b[0;32m    716\u001b[0m         config_path, overrides\u001b[38;5;241m=\u001b[39moverrides, interpolate\u001b[38;5;241m=\u001b[39minterpolate\n\u001b[0;32m    717\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: [E053] Could not read config file from C:\\Users\\soumya nanditha\\anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-2.2.0\\config.cfg"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Read the cleaned text from the CSV file\n",
    "with open(\"imdb_reviews_cleaned.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize counters for parts of speech\n",
    "noun_count = 0\n",
    "verb_count = 0\n",
    "adj_count = 0\n",
    "adv_count = 0\n",
    "\n",
    "# Initialize counters for named entities\n",
    "entity_counts = Counter()\n",
    "\n",
    "# Process and analyze the text\n",
    "for line in lines[1:]:  # Skip the header row\n",
    "    parts = line.split(\",\")\n",
    "    cleaned_review = parts[-1]  # Assuming the cleaned text is in the last column\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(cleaned_review)\n",
    "\n",
    "    # Perform POS tagging and count different parts of speech\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun_count += 1\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            verb_count += 1\n",
    "        elif token.pos_ == \"ADJ\":\n",
    "            adj_count += 1\n",
    "        elif token.pos_ == \"ADV\":\n",
    "            adv_count += 1\n",
    "\n",
    "    # Perform named entity recognition and count entities\n",
    "    for ent in doc.ents:\n",
    "        entity_counts[ent.label_] += 1\n",
    "\n",
    "# Print the results\n",
    "print(\"Parts of Speech Analysis:\")\n",
    "print(\"Nouns:\", noun_count)\n",
    "print(\"Verbs:\", verb_count)\n",
    "print(\"Adjectives:\", adj_count)\n",
    "print(\"Adverbs:\", adv_count)\n",
    "\n",
    "print(\"\\nNamed Entity Recognition:\")\n",
    "for label, count in entity_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Dependency parsing and constituency parsing can be complex and require separate visualization tools\n",
    "# We will not print the trees here, but you can use spaCy's visualization capabilities for these tasks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWOtvT2rHNWy"
   },
   "source": [
    "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency parsing tree and Constituency parsing trees play a key role in semantics analysis, sentence structure analysis.Dependency parsing considers each word of sentence as a node and grammatical connections between different words as links.It follows a bottom-up approach.Whereas constituency parsing is based on context-free grammar and it follows a top-down approach.\n",
    "\n",
    "Constituency parsing tree indicates how words in a sentence can be merged/grouped together to form different sentences.It follows a hierarchical model.It can be used in actively identifying and classifying POS in sentences and tagging them and helps in forming clusters of them.\n",
    "\n",
    "Unlike Constituency parsing tree, dependency parsing tree gives more importance to connection between words and identifies various types of dependencies like subject-verb etc..This can prove useful in tasks like information extraction, sentiment analysis, ML etc..\n",
    "These both are useful to bettter understand the structure of a sentence."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
